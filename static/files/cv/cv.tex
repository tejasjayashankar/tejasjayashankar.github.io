\documentclass[10pt,margin,centered]{res}
\PassOptionsToPackage{hyphens}{url}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{color,xcolor,fdsymbol,enumitem}
\usepackage{fancyhdr}
\usepackage{titling}
\usepackage{fontawesome} % for fa symbols

\usepackage{libertine}
\usepackage{libertinust1math}


\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=black,
    pdftitle={Tejas' CV},
    bookmarks=true,
    pdfpagemode=FullScreen,
}
\newcommand\quelle[1]{{%
      \unskip\nobreak\hfil\penalty50
      % \hskip2em
      \hbox{}\nobreak\hfil\emph{#1}%
      \parfillskip=0pt \finalhyphendemerits=0 \par}}
      
\newcommand{\MYhref}[3][blue]{\href{#2}{\color{#1}{#3}}}
\newcommand{\textBlue}[1]{{\leavevmode\color{blue}#1}} % blue color over text and math
\newcommand{\lm}{15pt}

\oddsidemargin -.5in
\evensidemargin -.5in
\textwidth=6.0in
\itemsep=0in
\parsep=0in
% if using pdflatex:
%\setlength{\pdfpagewidth}{\paperwidth}
%\setlength{\pdfpageheight}{\paperheight} 

\newenvironment{list1}{
  \begin{list}{\ding{113}}{%
      \setlength{\itemsep}{0in}
      \setlength{\parsep}{0in} \setlength{\parskip}{0in}
      \setlength{\topsep}{0in} \setlength{\partopsep}{0in} 
      \setlength{\leftmargin}{0.17in}}}{\end{list}}
\newenvironment{list2}{
  \begin{list}{$\bullet$}{%
      \setlength{\itemsep}{0in}
      \setlength{\parsep}{0in} \setlength{\parskip}{0in}
      \setlength{\topsep}{0in} \setlength{\partopsep}{0in} 
      \setlength{\leftmargin}{0.2in}}}{\end{list}}
      
\long\def\comment#1{}

\newcommand{\ptitle}[1]{``#1''}
\newcommand{\tbf}[1]{\textbf{#1}}

% Section content highlighting (selected sections only)
\definecolor{SectionBG}{RGB}{242,245,250}
\newsavebox{\sectionbox}
\newenvironment{shadedsection}{%
  \par\medskip\noindent
  \begin{lrbox}{\sectionbox}%
  \begin{minipage}{\dimexpr\textwidth-2\fboxsep\relax}
  \vspace{0.6ex}%
}{%
  \vspace{0.6ex}%
  \end{minipage}%
  \end{lrbox}%
  \colorbox{SectionBG}{\usebox{\sectionbox}}%
  \par\medskip
}

\begin{document}
% \pagestyle{fancy}
% \thispagestyle{empty}

% \begin{center}
% \name{\centering \sc {Raaz Dwivedi} hi \vspace*{.05in}}  
% \end{center}
% \name{\centering \sc {Raaz Dwivedi} hi \vspace*{.05in}}
\name{\Large \sc{Tejas Jayashankar}}
% \address{A}
% \address{B}
\address{
\\[-3mm]
{
% \quad
% \href{mailto:raaz@seas.harvard.edu}{{\footnotesize \faEnvelope}~\small{raaz@seas.harvard.edu}}
% \qquad
% \qquad
% \qquad
% \qquad
% \, \,
% {\faInstitution} {MIT}
% \ 
% \,\,\,\,\,
\href{https://tejasjayashankar.github.io/}{{\faHome}~\small
{tejasjayashankar.github.io}}
% \ 
% \qquad
% \qquad
% \href{mailto:raaz@seas.harvard.edu}{{\footnotesize \faEnvelope}~\small{raaz@seas.harvard.edu}}
% % \ 
\,\,\,\,
\href{mailto:tejasj@mit.edu}{{\footnotesize \faEnvelope}~\small{tejasj@mit.edu}}
\,\,\,\,
\faMobile~\href{tel:6303918118}{\small{(630) 391-8118}}
% \ 
\,
% \href{mailto:abhinshah02@gmail.com}{{\footnotesize \faEnvelope}~\small{abhinshah02@gmail.com}}
% \ 
\,\,\,\,
% \qquad
% \qquad
% \qquad
% \qquad
\href{https://scholar.google.com/citations?user=gjN_lUoAAAAJ&hl=en}{\large
\faGraduationCap}
% \ 
\,
\,
\href{https://github.com/tkj516}{\large
\faGithub}
% \ 
\,
\,
\href{https://www.linkedin.com/in/tkj97/}{\large
\faLinkedin}
% \,
% \,
% \href{https://twitter.com/AbhinShah2}{\large
% \faTwitter}
}
}
\begin{resume}
\vspace{-5mm}
{\raggedleft{
% \noindent
\makebox[\linewidth]{\rule{15.35cm}{0.4pt}}}
}
\vspace{-6mm}

\section{
% \faGraduationCap\ 
\sc Education} 
% \faUniversity\ 
{\bf Massachusetts Institute of Technology} (MIT)
\quelle{Cambridge, MA}
\vspace{-4mm}
 Ph.\! D. in Electrical Engineering and Computer Science 
 \quelle{2022---2025}
 \vspace{-4mm}
\textbf{Thesis:} \href{https://dspace.mit.edu/handle/1721.1/164063}{Score Estimation for Generative Modeling}
\quelle{GPA: 5.00/5.00}
\vspace{-4mm}
Advisor: \emph{Prof. Gregory W. Wornell}\\
\vspace{-4mm}

{\bf Massachusetts Institute of Technology} (MIT)
\quelle{Cambridge, MA}
\vspace{-4mm}
Master of Science in Electrical Engineering and Computer Science
\quelle{2019---2022}


% \faGraduationCap\ 
{\bf University of Illinois at Urbana-Champaign} (UIUC)\quelle{Champaign, IL} 
\vspace{-4mm}
Bachelor of Science in Electrical Engineering with Highest Honors
% \quelle{CGPA: 9.61/10.00} 
\quelle{2015---2019}
\vspace{-4mm}
% Indian Institute of Technology, Bombay, India \\
Minor in Mathematics
 \vspace{-2mm}
%----------------------------------------------------------------------------------------
% COMPUTER SKILLS SECTION
%----------------------------------------------------------------------------------------
 
%----------------------------------------------------------------------------------------
% PROFESSIONAL EXPERIENCE SECTION
%----------------------------------------------------------------------------------------
 
% \section{
% % \faPencilSquareO\ 
% \sc Research Interests} Generative Modeling, Diffusion Models, Representation Learning, Statistical Inference, Neural Compression

% \vspace{-2mm}
% \section{
% % \faPencilSquareO\ 
% \sc Technical Skills} PyTorch, JAX, Tensorflow, Diffusion Models, Transformers, Consistency Models, Normalizing Flows, VQ-VAEs, GANs, Information Theory, Distributed Training, Python, C++, C, Linux, Docker, Git

\section{
\sc Research Interests
}
Diffusion Models, Score Estimation, Few-step Generative Models, LLM Post-training, Reward Modeling, Neural Compression, Signal Processing
\vspace{-1mm}
\section{
\sc Software Skills
}
PyTorch, JAX, Tensorflow, Distributed training, Python, C++, C, Linux, Docker, Git

\vspace{-1mm}
\section{\sc Work Experience}
{\bf Meta Superintelligence Labs} \quelle{Menlo Park, CA}
\vspace{-4mm}
Role: \textit{Research Scientist} \quelle{June 2025 --- Present}
\begin{itemize}
    \item Built and trained next-generation neural speech codecs with an improved diffusion-based prior for production deployment alongside multimodal LLMs.
    \item Developing reward models and judges to improve speech aesthetic and semantic naturalness, leveraging RLHF and DPO for multimodal LLM post-training.
    \item Investigating diffusion distillation and few-step sampling methods to reduce latency and compute for diffusion-based token-to-waveform decoders.
\end{itemize}

% Generative Models, Representation Learning, Statistical Inference, Diffusion Models, Transformers, Consistency Models, Normalizing Flows, VQ-VAEs, GANs, Information Theory, Neural Compression

% \begin{itemize}
%     \item \textbf{Technical Skills:} 
%     \item \textbf{Software Skills:} 
% \end{itemize}

\newcommand{\vspone}{\vspace{-1mm}}
\section{\sc Research Internships}
{\bf Adobe Research} \quelle{San Jose, CA}
\vspace{-4mm}
Host: \textit{Nikos Vlassis} \quelle{May 2024 --- August 2024}
\begin{itemize}
    \item Trained one-step generative models by designing diffusion distillation algorithms leveraging maximum mean discrepancy (MMD) distribution matching.
\end{itemize}
\vspone


{\bf Google Research} \,\,\href{https://docs.google.com/presentation/d/12mXjO50qHUXiuk062CGNG6gNwtfHcO86uYLYbCLQmms/edit?usp=sharing&resourcekey=0-onMp2_GuNQTqEIEbvpB1AA}{\color{blue} \small
\faFilePowerpointO\  Final Presentation}\quelle{Cambridge, MA} 
\vspace{-4mm}
Hosts: \textit{Fabian Mentzer and David Minnen }\quelle{September 2022 --- April 2023}

\begin{itemize}
    \item Built multi-frame encoder/decoder components to scale transformer-based video compression training to longer sequences across TPUs, and introduced conditioning schemes enabling a single model to compress I/B/P frames with $>2\times$ faster inference.
\end{itemize}
\vspone


{\bf Meta AI}\,\,\href{https://ieeexplore.ieee.org/document/10097147}{\color{blue} \small
\faFilePdfO\ IEEE paper}\quelle{Menlo Park, CA}
\vspace{-4mm}
Hosts: \textit{Vimal Manohar and Qing He} \quelle{May 2022 --- September 2022}
\begin{itemize}
    \item Designed a HiFiGAN-based singing voice converter using ASR-fine-tuned Wav2Vec 2.0 features and a parallel bank of transposed convolutions (PBTC) for $f0$ modeling, and modeled rich vocal harmonics via strided/dilated transposed-convolution filterbanks.
\end{itemize}
\vspone


{\bf Meta AI} \,\,\href{https://ieeexplore.ieee.org/document/9747419}{\color{blue} \small
\faFilePdfO\ IEEE paper}\quelle{Cambridge, MA}
\vspace{-4mm}
Host: \textit{Qing He }\quelle{June 2021---September 2021}
\begin{itemize}
    \item Trained a variable-bitrate (3.2--12.8 kbps) neural speech codec with a hierarchical VQ-VAE backbone and adjustable compute, robust to packet losses up to 120 ms; MOS studies showed the lowest-bitrate setting outperformed Codec2, Opus (6 kbps), and Lyra.
\end{itemize}
\vspone


{\bf Mitsubishi Electric Research Labs} \,\,\href{https://arxiv.org/pdf/2006.01906}{\color{blue} \small
\faFilePdfO\ ISCA paper}\quelle{Cambridge, MA}
\vspace{-4mm}
Hosts: \textit{Jonathan Le Roux and Pierre Moulin }\quelle{March 2019 --- April 2019}
\begin{itemize}
\item Leveraged dropout-based uncertainty to detect audio attacks on ASR systems, achieving detection accuracies of 89\%, 92\%, and 94\% on noise-robust, auditory-masked, and urban-sound adversarial attacks, respectively.
\end{itemize}
\vspone
\vspace{-1mm}

\section{\sc Publications, Technical Reports, Patents}
% ; title is hyperlinked to the pdf of the paper)}}
{\footnotesize{($\star$ denotes equal contribution; title is hyperlinked to the online pdf of the paper)}}
\begin{enumerate}[label={\arabic*.},leftmargin=*]
  % \setcounter{enumi}{4}
  \item \textbf{Tejas Jayashankar}, \href{https://dspace.mit.edu/handle/1721.1/164063}{``Score Estimation for Generative Modeling''}, \textit{Doctoral thesis, Massachusetts Institute of Technology}\quelle{2025}
  \item \textbf{Tejas Jayashankar}$^\star$,\, Jongha Jon Ryu$^\star$\, Gregory W. Wornell, \href{https://arxiv.org/abs/2502.09609}{\ptitle{Score-of-Mixture Training: Training One-Step Generative Models Made Simple via Score Estimation of Mixture Distributions}}, \textit{International Conference on Machine Learning (ICML)} \,\,{\color{red}{\textbf{Spotlight: Top 2.6\% of papers} }\color{black}\quelle{2025}
  \item \textbf{Tejas Jayashankar}$^\star$,\, Jongha Jon Ryu$^\star$,\, Xiangxiang Xu,\, Gregory W. Wornell, \href{https://openreview.net/pdf?id=zX27NDlfcu}{\ptitle{Lifted Residual Score Estimation}}, \textit{ICML Workshop on Structured Probabilistic Inference \& Generative Modeling} \quelle{2024}
  \item \textbf{Tejas Jayashankar},\, Binoy Kurien,\, Alejandro Lancho,\, Gary C.F. Lee,\, Yury Polyanskiy,\, Amir Weiss,\, Gregory W. Wornell, \href{https://ieeexplore.ieee.org/document/10627554}{\ptitle{The Data-Driven Radio Frequency Signal Separation Challenge}}, \textit{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)} \quelle{2024}
  \item \textbf{Tejas Jayashankar},\, Gregory W. Wornell, \href{https://patents.google.com/patent/WO2024030698A1/en?oq=WO+2024%2f030698}{\ptitle{Model-code Separation Architecture for Data Compression using Sum-Product Networks}}, {\color{blue}\textit{International Patent WO 2024/030698}}\quelle{2024}
  \item \textbf{Tejas Jayashankar},\, Gary C. F. Lee,\, Alejandro Lancho,\, Amir Weiss,\, Yury Polyanskiy,\, Gregory W. Wornell, \href{https://openreview.net/pdf?id=BFGQQKicuu}{\ptitle{Score-based Source Separation with Applications to Digital Communication Signals}}, \textit{Advances in Neural Information Processing Systems (NeurIPS)} \quelle{2023}
  \item \textbf{Tejas Jayashankar},\, Jilong Wu,\, Leda Sari,\, David Kant,\, Vimal Manohar,\, Qing He, \href{https://ieeexplore.ieee.org/document/10097147}{\ptitle{Self-supervised Representations for Singing Voice Conversion}}, \textit{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}\quelle{2023}
  \item \textbf{Tejas Jayashankar}, \href{https://dspace.mit.edu/handle/1721.1/148612}{\ptitle{Image Compression using Sum-Product Networks}}, \textit{Master's thesis, Massachusetts Institute of Technology} \quelle{2022}
  \item \textbf{Tejas Jayashankar},\, Thilo Koehler,\, Kaustubh Kalgaonkar,\, Zhiping Xiu,\, Jilong Wu,\, Ju Lin,\, Prabhav Agrawal,\, Qing He, \href{https://ieeexplore.ieee.org/document/9747419}{\ptitle{Architecture for Variable Bitrate Neural Speech Codec with Configurable Computation Complexity}}, \textit{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)} \quelle{2022}
  \item Jonathan Le Roux,\, \textbf{Tejas Jayashankar},\, Pierre Moulin, \href{https://patents.google.com/patent/WO2021205746A1/en}{\ptitle{System and Method for Detecting Adversarial Attacks}}, {\color{blue}\textit{US Patent US16/84426}} \quelle{2021}
  \item \textbf{Tejas Jayashankar},\, Jonathan Le Roux,\, Pierre Moulin, \href{https://arxiv.org/pdf/2006.01906}{\ptitle{Detecting Audio Attacks on ASR Systems with Dropout Uncertainty}}, \textit{ INTERSPEECH} \quelle{2020}
  \item \textbf{Tejas Jayashankar},\, Pierre Moulin,\, Thierry Blu,\, Christopher Gilliam, \href{https://ieeexplore.ieee.org/document/8803484}{\ptitle{LAP-Based Video Frame Interpolation}}, \textit{IEEE International Conference on Image Processing (ICIP)} \quelle{2019}
\end{enumerate}


\section{
% \faNewspaperO\ 
\sc Awards And Achievements}
Claude E. Shannon Fellowship, MIT 
\quelle{2024---2025}
\vspone
\vspace{-2mm}

Fano Fellowship \& Hewlett Packard 2 Fellowship, MIT
\quelle{2019---2020}
\vspone
\vspace{-2mm}

{Bronze Tablet} for being in top 2\% of the graduating class, UIUC
\quelle{2019}
\vspone
\vspace{-2mm}

{Edward C. Jordan Award} for exemplary undergraduate research, UIUC
\quelle{2017}
\vspone
\vspace{-2mm}

{Jules D. Falzer Scholarship}, UIUC
\quelle{2017--2018}
\vspone


\section{\sc Leadership \& Teaching} 
\textbf{Leadership Experience}
\begin{itemize}[leftmargin=\lm]
    \item Student Advisor, MIT EECS Visiting Committee of Scholars and Professionals \quelle{2022}
    \item President, MIT EECS Graduate Student Association \quelle{2021---2022}
    \item President, UIUC Tau Beta Pi Chapter \quelle{2018---2019}
\end{itemize}
\textbf{Teaching and Mentoring Experience}
% \itemsep0em
\begin{itemize}[leftmargin=\lm]
  \item \textbf{Research Mentor}: Advised undergraduate students in research related to reinforcement learning, diffusion models and NeRFs\quelle{2021 \& 2024}
  \item \textbf{Teaching Assistant}: Led office hours and recitations for graduate level statistical inference course. Topics included probabilistic graphical models, variational inference, belief propagation and MCMC. Overall rating of 6.9/7.0 \quelle{2021}
  \item \textbf{Lab Instructor}: Digital signal processing in Python and MATLAB \quelle{2018---2019}
\end{itemize}
% \vsep
\vspace{-2mm}



% \section{\sc  References }
% \begin{table}[h]
% % \centering
% \begin{tabular}{l@{\hskip 0.5in}l@{\hskip 0.5in}l}
%  \sc{Devavrat Shah} & \sc{Gregory W. Wornell} & \sc{Alberto Abadie}  \\
%   Professor of EECS, MIT  & Professor of EECS, MIT & Professor of Economics, MIT \\
%     {Ph.\! D., Advisor} & {Ph.\! D., Advisor} & {Ph.\! D., Advisor} \\
%   \href{mailto:devavrat@mit.edu}{{\footnotesize\faEnvelope}~\small{devavrat@mit.edu}}  & 
%   \href{mailto:gww@mit.edu}{{\footnotesize\faEnvelope}~\small{gww@mit.edu}} &
%   \href{mailto:abadie@mit.edu}{{\footnotesize\faEnvelope}~\small{abadie@mit.edu}} 
% \end{tabular}
% \end{table}

\end{resume}
\end{document}