
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"About Me\nI am a final year PhD student in the EECS department at MIT advised by Professor Gregory Wornell. I received my M.S. degree in EECS from MIT in January 2022 and my B.S. degree in Electrical Engineering from the University of Illinois at Urbana-Champaign in 2019. My research interests lie at the intersection of generative modeling and representation learning. My current interests are in developing new techniques for score-based generative modeling such as improved techniques for training diffusion models and using these models for designing new one-step generators for downstream tasks such as inverse problems. I am also generally interested in the interplay between information theory and representation learning and have worked on several projects related to neural compression with generative decoders such as vision transformers, GANs and diffusion models.\nResearch Internship Experience\nI have had the opportunity to complete multiple research internships in the past. Currently, I am wrapping up my internship at Adobe Research where I am working on one-step generative modeling by leveraging novel diffusion distillation techniques that enforce distribution similarity. Before this, I worked on transformer-based video compression architectures with Dr. Fabian Mentzer on the Neural Compression Team at Google Research (see slides). I also worked with Dr. Qing He and Dr. Vimal Manohar at Meta AI in 2021 and 2022 respectively where I worked on speech compression and singing voice conversion with generative models. I have also interned with Dr. Jonathan Le Roux at MERL in 2019, where I conducted research on adversarial attack detection.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"About Me\nI am a final year PhD student in the EECS department at MIT advised by Professor Gregory Wornell. I received my M.S. degree in EECS from MIT in January 2022 and my B.","tags":null,"title":"Tejas Jayashankar","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://tejasjayashankar.github.io/talk/example-talk.html","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk.html","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["**Tejas Jayashankar**","Jongha J. Ryu","Xiangxiang Xu","Gregory W. Wornell"],"categories":null,"content":"","date":1719792000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719792000,"objectID":"d5fe8aab3d2945c4579e56caae3d7b0d","permalink":"https://tejasjayashankar.github.io/publication/2024-lifted-sm.html","publishdate":"2024-07-01T00:00:00Z","relpermalink":"/publication/2024-lifted-sm.html","section":"publication","summary":"This paper proposes two new techniques to im- prove the accuracy of score estimation. The first proposal is a new objective function called the lifted score estimation objective, which serves as a replacement for the score matching (SM) ob- jective. Instead of minimizing the expected l2 distance between the learned and true score mod- els, the proposed objective operates in the lifted space of the outer-product of a vector-valued func- tion with itself. The distance is defined as the ex- pected squared Frobenius norm of the difference between such matrix-valued objects induced by the learned and true score functions. The second idea is to model and learn the residual approxi- mation error of the learned score estimator, given a base score model architecture. We empirically demonstrate that the combination of the two ideas called lifted residual score estimation outperforms sliced SM in training VAE and WAE with implicit encoders, and denoising SM in training diffusion models, as evaluated by downstream metrics of sample quality such as the FID score.","tags":null,"title":"Lifted Residual Score Estimation","type":"publication"},{"authors":null,"categories":null,"content":"Score estimators lie at the heart of modern generative models, enabling the design and training of the latest generation of diffusion models based on Gaussian noise corruption processes. In this work we propose a new technique for learning the score of an underlying probability measure by defining a new objective in the lifted space of matrix valued objects. We show that this new objective can be optimized without any additional computational or memory overhead than existing score matching objectives. Moreover, we empirically demonstrate that the resulting method can lead to improvements in FID for generative modeling using diffusion models on the CIFAR-10 dataset and for implicit models trained on the CelebA dataset.\nAbstract\nThis paper proposes two new techniques to improve the accuracy of score estimation. The first proposal is a new objective function called the lifted score estimation objective, which serves as a replacement for the score matching (SM) objective. Instead of minimizing the expected l2-distance between the learned and true score models, the proposed objective operates in the lifted space of the outer-product of a vector-valued function with itself. The distance is defined as the expected squared Frobenius norm of the difference between such matrix-valued objects induced by the learned and true score functions. The second idea is to model and learn the residual approximation error of the learned score estimator, given a base score model architecture. We empirically demonstrate that the combination of the two ideas called lifted residual score estimation outperforms sliced SM in training VAE and WAE with implicit encoders, and denoising SM in training diffusion models, as evaluated by downstream metrics of sample quality such as the FID score.\n","date":1719792000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719792000,"objectID":"4469e15c71e4f9c352b629664d5bfeca","permalink":"https://tejasjayashankar.github.io/news/2024-lifted-sm.html","publishdate":"2024-07-01T00:00:00Z","relpermalink":"/news/2024-lifted-sm.html","section":"news","summary":"Recent work on improved score-estimation for diffusion models and implicit models presented at ICML SPIGM Workshop 2024","tags":["Research"],"title":"Recent work on improved score-estimation for diffusion models and implicit models accepted at ICML SPIGM Workshop 2024!","type":"news"},{"authors":null,"categories":null,"content":"Our latest paper on score-based methods for source separation with applications to digital communication signals with underlying discrete structures was accepted for a poster presentation at NeurIPS 2023. Please refer the abstract pasted below and to the links above for more information.\nAbstract\nWe propose a new method for separating superimposed sources using diffusion-based generative models. Our method relies only on separately trained statistical priors of independent sources to establish a new objective function guided by maximum a posteriori estimation with an $\\alpha$-posterior, across multiple levels of Gaussian smoothing. Motivated by applications in radio-frequency (RF) systems, we are interested in sources with underlying discrete nature and the recovery of encoded bits from a signal of interest, as measured by the bit error rate (BER). Experimental results with RF mixtures demonstrate that our method results in a BER reduction of 95% over classical and existing learning-based methods. Our analysis demonstrates that our proposed method yields solutions that asymptotically approach the modes of an underlying discrete distribution. Furthermore, our method can be viewed as a multi-source extension to the recently proposed score distillation sampling scheme, shedding additional light on its use beyond conditional sampling\n","date":1698796800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698796800,"objectID":"d7abbf4ce6883d75cca79b9e52a05073","permalink":"https://tejasjayashankar.github.io/news/2023-score-based-scss.html","publishdate":"2023-11-01T00:00:00Z","relpermalink":"/news/2023-score-based-scss.html","section":"news","summary":"Latest paper accepted for poster presentation at NeurIPS 2023!","tags":["Research"],"title":"Latest paper on score-based methods for single-channel source separation accepted at NeurIPS 2023","type":"news"},{"authors":null,"categories":null,"content":"","date":1697328000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1697328000,"objectID":"01b5f0738efb9f4ac8fc3559d8fd6ca8","permalink":"https://tejasjayashankar.github.io/gallery/graphene.html","publishdate":"2023-10-15T00:00:00Z","relpermalink":"/gallery/graphene.html","section":"gallery","summary":"","tags":null,"title":"Wave in graphene","type":"gallery"},{"authors":null,"categories":null,"content":"","date":1696896000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696896000,"objectID":"e9441bf62787bdcbbf4f79a8c7ec421a","permalink":"https://tejasjayashankar.github.io/gallery/fullrene.html","publishdate":"2023-10-10T00:00:00Z","relpermalink":"/gallery/fullrene.html","section":"gallery","summary":"","tags":null,"title":"Fullerene collision","type":"gallery"},{"authors":null,"categories":null,"content":"","date":1696464000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696464000,"objectID":"a4afb40bb80bd0d47a437bd23e31f11e","permalink":"https://tejasjayashankar.github.io/gallery/ring.html","publishdate":"2023-10-05T00:00:00Z","relpermalink":"/gallery/ring.html","section":"gallery","summary":"","tags":null,"title":"The molecular ring","type":"gallery"},{"authors":["**Tejas Jayashankar**","Gary C.F. Lee","Alejandro Lancho","Amir Weiss","Yury Polyanksiy","Gregory Wornell"],"categories":null,"content":"","date":1687737600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687737600,"objectID":"104de323163cb04ebf243c9436856e79","permalink":"https://tejasjayashankar.github.io/publication/2023-score-based-source-separation.html","publishdate":"2023-06-26T00:00:00Z","relpermalink":"/publication/2023-score-based-source-separation.html","section":"publication","summary":"We propose a new method for separating superimposed sources using diffusion-based generative models. Our method relies only on separately trained statistical priors of independent sources to establish a new objective function guided by maximum a posteriori estimation with an \\alpha-posterior, across multiple levels of Gaussian smoothing. Motivated by applications in radio-frequency (RF) systems, we are interested in sources with underlying discrete nature and the recovery of encoded bits from a signal of interest, as measured by the bit error rate (BER). Experimental results with RF mixtures demonstrate that our method results in a BER reduction of 95% over classical and existing learning-based methods. Our analysis demonstrates that our proposed method yields solutions that asymptotically approach the modes of an underlying discrete distribution. Furthermore, our method can be viewed as a multi-source extension to the recently proposed score distillation sampling scheme, shedding additional light on its use beyond conditional sampling.","tags":null,"title":"Score-based Source Separation with Applications to Digital Communication Signals","type":"publication"},{"authors":["**Tejas Jayashankar**","Jilong Wu","Leda Sari","David Kant","Vimal Manohar","Qing He"],"categories":null,"content":"","date":1685836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685836800,"objectID":"3c55edbe8fbdbd360118c389baf71f7a","permalink":"https://tejasjayashankar.github.io/publication/2023-self-supervised-representations.html","publishdate":"2023-06-04T00:00:00Z","relpermalink":"/publication/2023-self-supervised-representations.html","section":"publication","summary":"A singing voice conversion model converts a song in the voice of an arbitrary source singer to the voice of a target singer. Recently, methods that leverage self-supervised audio representations such as HuBERT and Wav2Vec 2.0 have helped further the state-ofthe-art. Though these methods produce more natural and melodic singing outputs, they often rely on confusion and disentanglement losses to render the self-supervised representations speaker and pitch-invariant. In this paper, we circumvent disentanglement training and propose a new model that leverages ASR fine-tuned self-supervised representations as inputs to a HiFi-GAN neural vocoder for singing voice conversion. We experiment with different f0 encoding schemes and show that an f0 harmonic generation module that uses a parallel bank of transposed convolutions (PBTC) alongside ASR fine-tuned Wav2Vec 2.0 features results in the best singing voice conversion quality. Additionally, the model is capable of making a spoken voice sing. We also show that a simple f0 shifting scheme during inference helps retain singer identity and bolsters the performance of our singing voice conversion model. Our results are backed up by extensive MOS studies that compare different ablations and baselines.","tags":null,"title":"Self-Supervised Representations for Singing Voice Conversion","type":"publication"},{"authors":null,"categories":null,"content":"I attended my first in-person CVPR in Vancouver. Got the chance to meet some colleagues and learn a lot about some of the latest research out there in generative modeling and representation learning.\n","date":1685577600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685577600,"objectID":"60feefda5eef24ba4276054ff3785ffe","permalink":"https://tejasjayashankar.github.io/news/2023-cvpr.html","publishdate":"2023-06-01T00:00:00Z","relpermalink":"/news/2023-cvpr.html","section":"news","summary":"Attended CVPR 2023 in Vancouver!","tags":["Personal"],"title":"Attended CVPR 2023 in Vancouver","type":"news"},{"authors":null,"categories":null,"content":"Wrapped up my internship at Google Research where I worked with Dr. Fabian Mentzer on the Neural Compression team on transformer-based video compression architectures. Please refer to slides for a summary of our results.\n","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682899200,"objectID":"ac5e9177f48bd521275db5574542d7e8","permalink":"https://tejasjayashankar.github.io/news/2023-google-research.html","publishdate":"2023-05-01T00:00:00Z","relpermalink":"/news/2023-google-research.html","section":"news","summary":"Completed my video compression-related student researcher internship with Dr. Fabian Mentzer.","tags":["Research"],"title":"Wrapped up my PhD Student Researcher Position at Google Research","type":"news"},{"authors":null,"categories":[],"content":" Tests\n","date":1674172800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674172800,"objectID":"60e79cb28829481c20d3db0f4695ad7c","permalink":"https://tejasjayashankar.github.io/blog/about-me.html","publishdate":"2023-01-20T00:00:00Z","relpermalink":"/blog/about-me.html","section":"blog","summary":"Details.","tags":[],"title":"About Me","type":"blog"},{"authors":["Jonathan Le Roux","**Tejas Jayashankar**","Pierre Moulin"],"categories":null,"content":"","date":1664841600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664841600,"objectID":"ce94185929b2707876cf99147c52e7f6","permalink":"https://tejasjayashankar.github.io/publication/2022-system-and-method.html","publishdate":"2022-10-04T00:00:00Z","relpermalink":"/publication/2022-system-and-method.html","section":"publication","summary":"A linguistic system for transcribing an input, where the linguistic system comprises a processor configured to execute a neural network multiple times while varying weights of at least some nodes of the neural network to produce multiple transcriptions of the input. Further, determine a distribution of pairwise distances of the multiple transcriptions; determine a legitimacy of the input based on the distribution; and transcribe the input using stored weights of the nodes of the neural network when the input is determined as legitimate to produce a final transcription of the input.","tags":null,"title":"System and Method for Detecting Adversarial Attacks","type":"publication"},{"authors":["**Tejas Jayashankar**","Thilo Koehler","Kaustubh Kalgaonkar","Zhiping Xiu","Jilong Wu","Ju Lin","Prabhav Agrawal","Qing He"],"categories":null,"content":"","date":1653264000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653264000,"objectID":"7b9d9065489f03cfe39c3f6bb3b96d0d","permalink":"https://tejasjayashankar.github.io/publication/2021-variable-rate-speech-codec.html","publishdate":"2022-05-23T00:00:00Z","relpermalink":"/publication/2021-variable-rate-speech-codec.html","section":"publication","summary":"Low bitrate speech codecs have become an area of intense research. Traditional speech codecs, which use signal processing methods to encode and decode speech, often suffer from quality issues at low bitrates. A neural speech codec, which uses a deep neural network in the compression pipeline, can help alleviate this issue. In this paper we present a new neural speech codec that: 1) supports variable bitrates 2) supports packet losses of up to 120 ms and 3) can operate at low-compute and high-compute modes. Our codec uses a hierarchical VQ-VAE (HVQVAE) for encoding and decoding spectral features at different bitrates. The decoded features are fed to a vocoder for speech synthesis. Depending upon the end user’s computing resources, the decoder either uses a powerful WaveRNN or a parametric vocoder for speech synthesis. Our experiments demonstrate that our HVQVAE + WaveRNN setup achieves high audio quality.","tags":null,"title":"Architecture for Variable Bitrate Neural Speech Codec with Configurable Computation Complexity","type":"publication"},{"authors":["**Tejas Jayashankar**"],"categories":null,"content":"","date":1643673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643673600,"objectID":"c042b7e38d5a7575aa529e289dbe1bef","permalink":"https://tejasjayashankar.github.io/publication/2022-image-compression-using-spns.html","publishdate":"2022-02-01T00:00:00Z","relpermalink":"/publication/2022-image-compression-using-spns.html","section":"publication","summary":"An estimated 79 zettabytes (1021 bytes) of data was generated worldwide in 2021 with even more data expected to be produced in the future. The effective storage and communication of such large amounts of data is an important problem. Data compression lies at the heart of the solution to this issue. The two aspect of data compression — data modeling and coding — are typically jointly designed. As a result, it is difficult to evolve compression standards without a complete modification of the entire architecture. Recently, a model-code separation architecture for compression was proposed with a model-free encoder and model-adaptive decoder. The architecture uses a data independent encoder, and it employs a probabilistic graphical model (PGM) to model the source structure in the decoder. Decoding is performed by running belief propagation over the graphical models representing the modeling and coding aspects of compression. In practical settings where we deal with naturally occurring data, e.g., CIFAR-10 images, the PGM underlying the source data is unknown. Existing structure learning algorithms for PGMs are inefficient for learning from large datasets and place additional constraints on the graphical model structure that diminishes a PGM’s representational power. Due to the difficulty of inference and learning in complex PGMs, the current model-code separation architecture is limited in its use for many real world applications. In this thesis, we develop a new separation architecture based on recently proposed sum-product networks (SPNs), a class of tractable probabilistic generative models, to model the source distribution. Our architecture strikes a balance between efficient learning of source structure and fast lossless decoding. We show that SPNs admit efficient parameter learning via gradient descent to learn statistical structure in synthetic and naturally occurring images. Furthermore, through modifications to the SPN architecture, we describe a procedure to assimilate external beliefs about the source and compute the marginal probabilities of all the source nodes in a single forward and backward pass of the SPN architecture. By using an SPN source model in place of a PGM, we obtain a new model-code separation architecture for compression. Throughout this thesis, we focus on the efficient implementation of our compression architecture. We take advantage of modern deep learning frameworks and GPUs to implement our entire architecture using parallelized tensor operations. As a result, we are able to bridge the gap between traditional statistical inference algorithms and modern deep learning models by carefully developing the SPN source-code belief propagation algorithm for source decoding. The resulting algorithm can decode grayscale sources in under 0.04 seconds. This work applies the proposed architecture for the lossless compression of binary and grayscale images. We compare our architecture against some of the most commonly used compression systems of today and theoretical limits. We show that our architecture achieves a 1.7× gain in compression rate over the state-of-the-art JBIG2 compressor on the binarized MNIST dataset. Furthermore, our architecture does not incur a performance penalty on grayscale sources and is still able to achieve a 1.4× gain in compression rate on the grayscale CIFAR-10 and the Fashion MNIST datasets, as compared against some of the best universal compressors. Extensive analysis on synthetic binary sources show that our architecture can achieve near theoretical limits of compression and match the performance of baseline separation architectures with known PGM structure.","tags":null,"title":"Image Compression using Sum-Product Networks","type":"publication"},{"authors":["**Tejas Jayashankar**","Jonathan Le Roux","Pierre Moulin"],"categories":null,"content":"","date":1602720000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602720000,"objectID":"1ae2e7ec5ef441001ba4d9a863d6039d","permalink":"https://tejasjayashankar.github.io/publication/2020-detecting-audio-attacks.html","publishdate":"2020-10-15T00:00:00Z","relpermalink":"/publication/2020-detecting-audio-attacks.html","section":"publication","summary":"Various adversarial audio attacks have recently been developed to fool automatic speech recognition (ASR) systems. We here propose a defense against such attacks based on the uncertainty introduced by dropout in neural networks. We show that our defense is able to detect attacks created through optimized perturbations and frequency masking on a state-of-the-art end-to-end ASR system. Furthermore, the defense can be made robust against attacks that are immune to noise reduction. We test our defense on Mozilla's CommonVoice dataset, the UrbanSound dataset, and an excerpt of the LibriSpeech dataset, showing that it achieves high detection accuracy in a wide range of scenarios.","tags":null,"title":"Detecting Audio Attacks on ASR Systems with Dropout Uncertainty","type":"publication"},{"authors":["**Tejas Jayashankar**","Pierre Moulin","Thierry Blu","Chris Gilliam\""],"categories":null,"content":"","date":1569110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569110400,"objectID":"0fd347c832380ba139c88f5e0d7748bc","permalink":"https://tejasjayashankar.github.io/publication/2019-lap-based-vfi.html","publishdate":"2019-09-22T00:00:00Z","relpermalink":"/publication/2019-lap-based-vfi.html","section":"publication","summary":"High-quality video frame interpolation often necessitates accurate motion estimation, which can be obtained using modern optical flow methods. In this paper, we use the recently proposed Local All-Pass (LAP) algorithm to compute the optical flow between two consecutive frames. The resulting flow field is used to perform interpolation using cubic splines. We compare the interpolation results against a well-known optical flow estimation algorithm as well as against a recent con-volutional neural network scheme for video frame interpolation. Qualitative and quantitative results show that the LAP algorithm performs fast, high-quality video frame interpolation, and perceptually outperforms the neural network and the Lucas-Kanade method on a variety of test sequences.","tags":null,"title":"LAP-based Video Frame Interpolation","type":"publication"},{"authors":null,"categories":null,"content":"Update will be posted here.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"006f6f30ba9f03341dfbc41d9d1dd847","permalink":"https://tejasjayashankar.github.io/project/hybrid-nanoporous-materials.html","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/hybrid-nanoporous-materials.html","section":"project","summary":"Ongoing MSCA project","tags":["Nanofluids"],"title":"Hybrid nanoporous materials for the separation of fluid mixtures","type":"project"}]